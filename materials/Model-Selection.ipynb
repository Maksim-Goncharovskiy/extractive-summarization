{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fc033b-ee5b-49a7-ab70-19359d92a84f",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size: 40px\"> «Экстрактная суммаризация» </h1></center>\n",
    "<center><h1 style=\"font-size: 30px\"> Сравнение алгоритмов и моделей на разных метриках </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2fe0ad-cf8e-41db-af9c-2b7dfdea0e1a",
   "metadata": {},
   "source": [
    "# Содержание\n",
    "### 0. [Используемые датасет и метрики](#chapter0)\n",
    "### 1. [Алгоритмы экстрактной суммаризации из библиотеки sumy](#chapter1)\n",
    "#### 1.1. [TextRank](#chapter1.1)\n",
    "#### 1.2. [LexRank](#chapter1.2)\n",
    "#### 1.3. [LSA](#chapter1.3)\n",
    "#### 1.4. [KL Divergence](#chapter1.4)\n",
    "#### 1.5. [Luhn](#chapter1.5)\n",
    "### 2. [Предобученный ruBertSum](#chapter2)\n",
    "### 3. [Результаты](#chapter3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d019d2b-136b-496f-a8ae-36ddc55c642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Библиотека с реализациями алгоритмов экстрактивной суммаризации\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoConfig\n",
    "\n",
    "# Предобученный на экстрактивную суммаризацию берт\n",
    "from summarizer import Summarizer\n",
    "\n",
    "from googletrans import Translator, LANGUAGES\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Метрики\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f52cf6a-c9cd-42e3-a7c4-b5539e857c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7bdfa-98fc-445d-877f-85dde5258ac0",
   "metadata": {},
   "source": [
    "<center id=\"chapter0\"><h1 style=\"font-size: 24px\"> Используемые датасет и метрики </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f40bc1-5208-47ae-86ae-b7a0ebdbc3a8",
   "metadata": {},
   "source": [
    "### Датасет: CNN-extractive -> https://huggingface.co/datasets/eReverter/cnn_dailymail_extractive?row=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ff20b5-4e04-445e-9645-494e1a1ab5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"russian\" # Используемый язык, russian -> делать перевод\n",
    "\n",
    "have_russian_file = True # True -> есть русский датасет в файле, False - загрузка датасета через load_dataset\n",
    "path = \"./russian_data.pkl\" \n",
    "\n",
    "make_sample = True # True -> Взять подвыборку из датасета(особенно критично, если выбран русский, так как 20 строк переводит за минуту)\n",
    "sample_len = 5 # Длина подвыборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4264a9a1-d141-4998-aa6b-90e8c80eb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "df = None\n",
    "\n",
    "if have_russian_file:\n",
    "    data = pd.read_pickle(path)\n",
    "    df = pd.DataFrame(data[['ru_src', 'labels']].values, columns=['sentences', 'labels'])\n",
    "\n",
    "\n",
    "else:\n",
    "    dataset = load_dataset('eReverter/cnn_dailymail_extractive', split='validation')\n",
    "    if make_sample:\n",
    "        data = dataset.to_pandas().drop('tgt', axis=1).sample(sample_len, random_state=42)\n",
    "    else:\n",
    "        data = dataset.to_pandas().drop('tgt', axis=1)\n",
    "\n",
    "\n",
    "    if language == 'english':\n",
    "        data['src'] = data['src'].apply(lambda text: text.tolist())\n",
    "        df = pd.DataFrame(data[['src', 'labels']].values, columns=['sentences', 'labels'])\n",
    "    else:\n",
    "        translator = Translator()\n",
    "        data['src'] = data['src'].apply(lambda text: text.tolist())\n",
    "        data['ru_src'] = data['src'].apply(lambda sentences: [translator.translate(sentence, src='en', dest='ru').text for sentence in sentences])\n",
    "\n",
    "        df = pd.DataFrame(data[['ru_src', 'labels']].values, columns=['sentences', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e4f96e-7804-4970-ba55-ddd4ee53116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_summary(sentences, labels):\n",
    "    \"\"\" \n",
    "    Получение образцовой экстрактивной суммаризации по массиву предложений и по маске входящих в суммаризацию предложений\n",
    "    Параметры:\n",
    "        sentences - массив строк(предложений)\n",
    "        labels - маска предложений, 1 - предложение входит в суммаризацию, 0 - не входит\n",
    "    Возвращает:\n",
    "        строку\n",
    "    \"\"\"\n",
    "    labels = [x==1 for x in labels]\n",
    "    \n",
    "    reference_summary = np.array(sentences)[labels]\n",
    "\n",
    "    return ' '.join(reference_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bbb7da-623d-49ea-bd05-dd4dbe8e418c",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a9e9c-e527-4966-bdfd-069fd6efc1f6",
   "metadata": {},
   "source": [
    "Будем использовать Rouge-метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c976949e-dd95-4ba8-8764-a391e1279e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rouge-score\n",
    "#!pip install evaluate\n",
    "import rouge_score\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009ed778-65b1-46a7-81f2-2438bbd2d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate вроде бы позволяет считать метрики сразу для многих примеров, а не только для одного саммари\n",
    "scorer = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8c0f6d-81cb-4ada-930d-4bf08adb6562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge_scores(generated_summaries, reference_summaries):\n",
    "    \"\"\"\n",
    "    Получение ROUGE-метрик для массива полученных суммаризаций\n",
    "    Параметры:\n",
    "        generated_summaries - массив полученных алгоритмом суммаризаций\n",
    "        reference_summaries - массив соответствующих образцовых суммаризация\n",
    "    Возвращает:\n",
    "        словарь: ключ - метрика, значение - величина метрики\n",
    "    \"\"\"\n",
    "    return scorer.compute(\n",
    "        predictions=generated_summaries, \n",
    "        references=reference_summaries\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8cabd7-db55-4665-9449-62ca7df9fc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(CNN) Палестинская администрация официально с...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(CNN) Не говоря уже о кошках, у которых девят...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(CNN) Если вы в последнее время следили за но...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(CNN) Пятеро американцев, за которыми в течен...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(CNN) Студент Дьюка признался, что повесил пе...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>[Немигающие глаза смотрят с обезглавленных гол...</td>\n",
       "      <td>[1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>[Приложение, которое позволяет пользователям н...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>[Испанская больница утверждает, что провела «с...</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>[Ученые выявили новую сложную датировку., Мето...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>[Оператор спутникового телевидения DirecTV пре...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentences  \\\n",
       "0     [(CNN) Палестинская администрация официально с...   \n",
       "1     [(CNN) Не говоря уже о кошках, у которых девят...   \n",
       "2     [(CNN) Если вы в последнее время следили за но...   \n",
       "3     [(CNN) Пятеро американцев, за которыми в течен...   \n",
       "4     [(CNN) Студент Дьюка признался, что повесил пе...   \n",
       "...                                                 ...   \n",
       "4995  [Немигающие глаза смотрят с обезглавленных гол...   \n",
       "4996  [Приложение, которое позволяет пользователям н...   \n",
       "4997  [Испанская больница утверждает, что провела «с...   \n",
       "4998  [Ученые выявили новую сложную датировку., Мето...   \n",
       "4999  [Оператор спутникового телевидения DirecTV пре...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3                     [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]  \n",
       "4     [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "4995  [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4996  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4997  [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "4998  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, ...  \n",
       "4999  [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd22ab9-3c78-435d-817f-eb290a565da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>References</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Позже в том же месяце МУС начал предварительно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ее взяла к себе жительница Мозес-Лейк, штат Ва...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Он, конечно, министр иностранных дел Ирана. В ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В марте они заразились Эболой в Сьерра-Леоне, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN) Студент Дьюка признался, что повесил пет...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Немигающие глаза смотрят с обезглавленных голо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Приложение, которое позволяет пользователям на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Врачи заявили, что 27-часовая процедура восста...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Австралопитек Прометей жил примерно в то же вр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>В серии рекламных роликов, стартовавшей в октя...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             References\n",
       "0     Позже в том же месяце МУС начал предварительно...\n",
       "1     Ее взяла к себе жительница Мозес-Лейк, штат Ва...\n",
       "2     Он, конечно, министр иностранных дел Ирана. В ...\n",
       "3     В марте они заразились Эболой в Сьерра-Леоне, ...\n",
       "4     (CNN) Студент Дьюка признался, что повесил пет...\n",
       "...                                                 ...\n",
       "4995  Немигающие глаза смотрят с обезглавленных голо...\n",
       "4996  Приложение, которое позволяет пользователям на...\n",
       "4997  Врачи заявили, что 27-часовая процедура восста...\n",
       "4998  Австралопитек Прометей жил примерно в то же вр...\n",
       "4999  В серии рекламных роликов, стартовавшей в октя...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Дата фрейм, в который будем сохранять получающиеся суммаризации для каждой модели\n",
    "# Первый столбец - образцовая суммаризация, с которой будем сравнивать\n",
    "df_results = pd.DataFrame()\n",
    "df_results[\"References\"] = df[['sentences', 'labels']].apply(lambda cols: get_reference_summary(cols['sentences'], cols['labels']) , axis=1)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9762521-903c-4899-9681-749078b19010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все полученные значения метрик для всех алгоритмов будем хранить в датафрейме result_metrics\n",
    "\n",
    "columns = [\"rouge1\", \"rouge2\", \"rougeL\", 'rougeLsum']\n",
    "index = [\"TextRank\", \"LexRank\", \"LSA\", \"KL\", \"Luhn\", \"ruBertSum\"]\n",
    "\n",
    "result_metrics = pd.DataFrame(columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7773c75-56f2-4104-a5ef-d90253e5857e",
   "metadata": {},
   "source": [
    "<center id=\"chapter1\"><h1 style=\"font-size: 24px\"> 1. Алгоритмы экстрактной суммаризации из библиотеки sumy </h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75aeedf8-9753-4f0d-b43a-d974bcfa319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parsed_text(text):\n",
    "    \"\"\"\n",
    "    Парсит текст для алгоритмов из библиотеки sumy\n",
    "    Параметры:\n",
    "        text - одна строка\n",
    "    \"\"\"\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
    "    return parser.document\n",
    "\n",
    "def get_summary(summarizer, sentences, labels):\n",
    "    \"\"\"\n",
    "    Получение суммаризации при помощи алгоритмов из библиотеки sumy\n",
    "    Параметры:\n",
    "        summarizer - объект-суммаризатор, один из библиотеки sumy\n",
    "        sentences - массив строк(предложений)\n",
    "        labels - маска текста. Нужно, чтоб посчитать количество предложений, входящих в образцовую суммаризацию.\n",
    "    Возвращает:\n",
    "        строку - суммаризацию\n",
    "    \"\"\"\n",
    "    text = ' '.join(sentences)\n",
    "    parsed_text = get_parsed_text(text)\n",
    "    summary = summarizer(parsed_text, int(sum(labels)))\n",
    "    \n",
    "    str_summary = ''\n",
    "    for sentence in summary:\n",
    "        str_summary+=str(sentence)  \n",
    "    return str_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b5eb2-26c2-4dea-ae3f-ad1dba390db9",
   "metadata": {},
   "source": [
    "## 1.1. TextRank <a id=\"chapter1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "464b5748-0bcb-419f-8bb2-b6a4956f4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "summarizer = TextRankSummarizer()\n",
    "\n",
    "df_results['TextRank'] = df[['sentences', 'labels']].apply(lambda cols: get_summary(summarizer, cols['sentences'], cols['labels']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff11d79-986b-4008-9214-5c98d2049b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.21126236796504436,\n",
       " 'rouge2': 0.10644054692734534,\n",
       " 'rougeL': 0.2070681671019003,\n",
       " 'rougeLsum': 0.2066887322169475}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict = get_rouge_scores(list(df_results['TextRank'].values), list(df_results[\"References\"].values))\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "436bd16c-7ed1-48a6-aa8c-061ace68e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    result_metrics.loc[\"TextRank\"][col] = metrics_dict[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31579881-c080-4045-84e4-dcbe60bb0bfc",
   "metadata": {},
   "source": [
    "## 1.2. LexRank <a id=\"chapter1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf7a1802-750f-409e-8014-73f0d1b0f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "\n",
    "summarizer_lex = LexRankSummarizer()\n",
    "\n",
    "df_results['LexRank'] = df[['sentences', 'labels']].apply(lambda cols: get_summary(summarizer_lex, cols['sentences'], cols['labels']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b95c169d-4016-405d-a9c2-ac09dbd96a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.23577795584900077,\n",
       " 'rouge2': 0.11843411223228903,\n",
       " 'rougeL': 0.23075763215107667,\n",
       " 'rougeLsum': 0.23048015865028315}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict = get_rouge_scores(list(df_results['LexRank'].values), list(df_results[\"References\"].values))\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7334e0bc-9c76-4c93-b869-12e999640225",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    result_metrics.loc[\"LexRank\"][col] = metrics_dict[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e95005-bf5f-4054-bdef-b9635c516487",
   "metadata": {},
   "source": [
    "## 1.3. LSA <a id=\"chapter1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c425faf-4a18-4866-8f92-25f6e8bdd1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "summarizer_lsa = LsaSummarizer()\n",
    "\n",
    "df_results['LSA'] = df[['sentences', 'labels']].apply(lambda cols: get_summary(summarizer_lsa, cols['sentences'], cols['labels']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39683df3-12cf-4a54-a0f6-7a926d7418a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.17382211322549318,\n",
       " 'rouge2': 0.07880977141765376,\n",
       " 'rougeL': 0.1707859184708569,\n",
       " 'rougeLsum': 0.17072070001283238}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict = get_rouge_scores(list(df_results['LSA'].values), list(df_results[\"References\"].values))\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "775d4923-6ff9-42b5-b347-1238c9dbec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    result_metrics.loc[\"LSA\"][col] = metrics_dict[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe454c-3e83-4d3c-b2a0-fc5760ce15fd",
   "metadata": {},
   "source": [
    "## 1.4. KL Divergence <a id=\"chapter1.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99f6d627-148d-4df9-a7f8-6594d88c3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.kl import KLSummarizer\n",
    "\n",
    "summarizer_kl = KLSummarizer()\n",
    "\n",
    "df_results['KL'] = df[['sentences', 'labels']].apply(lambda cols: get_summary(summarizer_kl, cols['sentences'], cols['labels']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d257a161-7935-45eb-b93f-f9fa6b1602f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.2034073291580784,\n",
       " 'rouge2': 0.09986930246110058,\n",
       " 'rougeL': 0.2001564415558217,\n",
       " 'rougeLsum': 0.19963947500316334}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict = get_rouge_scores(list(df_results['KL'].values), list(df_results[\"References\"].values))\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1267696b-2ef8-499d-946b-63958675a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    result_metrics.loc[\"KL\"][col] = metrics_dict[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5fab1-4916-4aac-a472-85452ec31d5f",
   "metadata": {},
   "source": [
    "## 1.5. Luhn <a id=\"chapter1.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74ff9a0c-036a-4709-b198-bfa69a10a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "\n",
    "summarizer_luhn = LuhnSummarizer()\n",
    "\n",
    "df_results['Luhn'] = df[['sentences', 'labels']].apply(lambda cols: get_summary(summarizer_luhn, cols['sentences'], cols['labels']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df6077d8-2600-436c-a94a-a29b53b66d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.22938170405622646,\n",
       " 'rouge2': 0.11306958886023438,\n",
       " 'rougeL': 0.22520965815539917,\n",
       " 'rougeLsum': 0.22504851552030047}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dict = get_rouge_scores(list(df_results['Luhn'].values), list(df_results[\"References\"].values))\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ec8368b-8344-471b-ac59-c116fb8077b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    result_metrics.loc[\"Luhn\"][col] = metrics_dict[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5230da-8bf4-4051-86a7-288086930b09",
   "metadata": {},
   "source": [
    "<center id=\"chapter2\"><h1 style=\"font-size: 24px\"> 2. Предобученный ruBertSum </h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dfa5b35-154c-418b-be8d-a8919a23d34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Объявляем модель, токенизатор, конфиг\n",
    "ext_model_name = 'DeepPavlov/rubert-base-cased' # берем русский берт как основу суммаризатора\n",
    "custom_tokenizer = BertTokenizer.from_pretrained(ext_model_name)\n",
    "custom_config = AutoConfig.from_pretrained(ext_model_name)\n",
    "\n",
    "# вывод скрытого состояния каждого слова = True. Это нужно, т.к. Summarizer работает именно с скрытыми состояниями (метаданными о тексте)\n",
    "custom_config.output_hidden_states=True\n",
    "custom_model = BertForSequenceClassification.from_pretrained(ext_model_name, config=custom_config)\n",
    "bertsum_model = Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer) # задаём русский берт как модель и токенизатор у суммаризатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945145c-c046-486e-a33f-2361f6e8db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['BertSum'] = df[['sentences', 'labels']].apply(lambda cols: bertsum_model(' '.join(cols['sentences']), num_sentences=sum(cols['labels'])),\n",
    "                                                          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42d696-7f4d-4211-9926-2fa912baa473",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = get_rouge_scores(list(df_results['BertSum'].values), list(df_results[\"References\"].values))\n",
    "metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ae128-0dec-4815-ac19-55e9d8f749f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns:\n",
    "    result_metrics.loc[\"ruBertSum\"][col] = metrics_dict[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba62faec-8717-4902-85da-22cd60101536",
   "metadata": {},
   "source": [
    "<center id=\"chapter3\"><h1 style=\"font-size: 24px\"> 3. Результаты </h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7fdd36-abc9-4701-b933-ee884d81c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a8a3b-57d9-42a2-9a88-e75de2fc4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics.to_csv(\"results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
